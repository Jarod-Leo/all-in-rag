# 文档加载及处理
在RAG系统中，我们经常需要处理各种格式的文档，包括结构化数据e.g.表格数据，半结构化数据e.g.带有元数据（metadata）的文档，以及非结构化数据比如纯文档、论文、PDF等。文档的模态也是多元化的，有纯文本的，也有纯图像的，当然最多的还是多模态的文档。此外文档的存储格式也有很多，包括word，pdf，markdown，json等等，所以这就导致了文档加载器的多样性，因为要处理不同形式的数据。当然目前在AI（主要是LLM,MLLM）的加持下也渐渐有一些文档加载器拥有多模态和多格式文档处理能力比如MinerU
## 一、文档加载器
在整个RAG系统中，数据加载是整个workflow的第一步，也是不可或缺的一步。文档加载器负责将各种格式的非结构化文档（如PDF、Word、Markdown、HTML等）转换为程序可以处理的结构化数据。数据加载的质量会直接影响后续的索引构建、检索效果和最终的生成质量。
### 1.1 主要功能
- **文档格式解析**将不同格式的文档（如PDF、Word、Markdown等）解析为文本内容。
- **元数据提取**在解析文档内容的同时，提取相关的元数据信息，如文档来源、页码等。
- **统一数据格式**在解析文档内容的同时，提取相关的元数据信息，如文档来源、页码。等。
### 1.2 当前主流RAG文档加载器
| 工具名称          | 主要特点                          | 适用场景                | 性能表现                    |
|-------------------|-----------------------------------|-------------------------|-----------------------------|
| PyMuPDF4LLM       | PDF→Markdown转换，OCR+表格识别    | 科研文献、技术手册      | 开源免费，GPU加速           |
| TextLoader        | 基础文本文件加载                  | 纯文本处理              | 轻量高效                    |
| DirectoryLoader   | 批量目录文件处理                  | 混合格式文档库          | 支持多格式扩展              |
| Unstructured      | 多格式文档解析                    | PDF、Word、HTML等       | 统一接口，智能解析          |
| FireCrawlLoader   | 网页内容抓取                      | 在线文档、新闻          | 实时内容获取                |
| LlamaParse        | 深度PDF结构解析                   | 法律合同、学术论文      | 解析精度高，商业API         |
| Docling           | 模块化企业级解析                  | 企业合同、报告          | IBM生态兼容                 |
| Marker            | PDF→Markdown，GPU加速             | 科研文献、书籍          | 专注PDF转换                 |
| MinerU            | 多模态集成解析                    | 学术文献、财务报表      | 集成LayoutLMv3+YOLOv8       |

## 二、Unstructured文档处理库
Unstructured是一个专业的文档处理库，专门设计用于RAG和AI微调场景的非结构化数据预处理。提供了统一的接口来处理多种文档格式，是目前最受欢迎的文档加载解决方案之一。
### 2.1 Unstructured的核心优势
**格式支持广泛**

- 支持多种文档格式：PDF、Word、Excel、HTML、Markdown等
- 统一的API接口，无需为不同格式编写不同代码

**智能内容解析**

- 自动识别文档结构：标题、段落、表格、列表等
- 保留文档元数据信息

### 2.2 支持的文档元素类型（部分）
Unstructured能够识别和分类以下文档元素：
| 元素类型          | 描述                                                                 |
|-------------------|----------------------------------------------------------------------|
| Title             | 文档标题                                                             |
| NarrativeText     | 由多个完整句子组成的正文文本，不包括标题、页眉、页脚和说明文字         |
| ListItem          | 列表项，属于列表的正文文本元素                                         |
| Table             | 表格                                                                 |
| Image             | 图像元数据                                                           |
| Formula           | 公式                                                                 |
| Address           | 物理地址                                                             |
| EmailAddress      | 邮箱地址                                                             |
| FigureCaption     | 图片标题/说明文字                                                    |
| Header            | 文档页眉                                                             |
| Footer            | 文档页脚                                                             |
| CodeSnippet       | 代码片段                                                             |
| PageBreak         | 页面分隔符                                                           |
| PageNumber        | 页码                                                                 |
| UncategorizedText | 未分类的自由文本                                                     |
| CompositeElement  | 分块处理时产生的复合元素*                                            |

### 2.3. 从Langchain封装到原始Unstructured
LangChain中高度封装了Unstructured库，我们可以直接调用LangChain的`UnstructuredMarkdownLoader加载文档，这样可以获得更大的灵活性和控制力。

#### 代码示例
```python
from unstructured.partition.auto import partition

# PDF文件路径
pdf_path = "../../data/C2/pdf/rag.pdf"

# 使用Unstructured加载并解析PDF文档
elements = partition(
    filename=pdf_path,
    content_type="application/pdf"
)

# 打印解析结果
print(f"解析完成: {len(elements)} 个元素, {sum(len(str(e)) for e in elements)} 字符")

# 统计元素类型
from collections import Counter
types = Counter(e.category for e in elements)
print(f"元素类型: {dict(types)}")

# 显示所有元素
print("\n所有元素:")
for i, element in enumerate(elements, 1):
    print(f"Element {i} ({element.category}):")
    print(element)
    print("=" * 60)

```
**partition函数参数解析：**

`filename`: 文档文件路径，支持本地文件路径
`content_type`: 可选参数，指定MIME类型（如"application/pdf"），可绕过自动文件类型检测
`file`: 可选参数，文件对象，与filename二选一使用
`url`: 可选参数，远程文档URL，支持直接处理网络文档
`include_page_breaks`: 布尔值，是否在输出中包含页面分隔符
`strategy`: 处理策略，可选"auto"、"fast"、"hi_res"等
`encoding`: 文本编码格式，默认自动检测
`partition`函数使用自动文件类型检测，内部会根据文件类型路由到对应的专用函数（如PDF文件会调用`partition_pdf`）。如果需要更专业的PDF处理，可以直接使用`from unstructured.partition.pdf import partition_pdf`，它提供更多PDF特有的参数选项，如OCR语言设置、图像提取、表格结构推理等高级功能，同时性能更优。

## 三、MinerU工具集
MinerU 的设计初衷是：为检索增强生成（RAG）系统提供“模块化、可插拔”的非结构化数据加载与预处理能力。它不仅支持文本，还兼顾图像、表格、PDF、网页和其他形式的非结构化内容，并能对不同数据源（如本地文件、数据库、云存储、网页抓取等）进行统一抽象与适配。
### 3.1 主要组件与功能
下面是MinerU的关键模块及其职责
| 模块                      | 功能           | 说明                                                                                             |
|---------------------------|----------------|--------------------------------------------------------------------------------------------------|
| SourceConnector           | 数据源接入     | 支持接入多种原始数据源，如文件系统、S3、数据库、HTTP/HTTPS 等                                   |
| DocumentParser            | 文档解析       | 对文本、PDF、Word、HTML、Markdown 等格式进行解析；若有图像或表格，可进一步调用子模块处理          |
| Segmenter / Chunker       | 文本切片       | 将大文档拆成多个片段（chunk），支持按句子、段落、滑窗、语义分割等策略                             |
| MetadataExtractor         | 元数据抽取     | 抽取作者、创建时间、标题、标签等结构化元信息，附加到文档片段                                     |
| Normalizer / Cleaner      | 文本清洗       | 去除空白、HTML 标签、控制字符、重复内容等，统一格式                                              |
| Vectorizer / Embedder 接口 | 嵌入抽取       | 提供与多种嵌入模型（如 OpenAI、Sentence-Transformers、CLIP 等）的对接能力                        |
| Storage Interface         | 存储接入       | 将处理好的文档片段保存到向量数据库、关系/键值数据库或分布式存储中                                |
### 3.2 MinerU的简单使用代码
```python
# 导入MinerU库，这是一个用于文档处理和分析的工具
from mineru import MinerU

# 初始化 MinerU，引入数据源和配置
miner = MinerU(
    # 配置数据源：支持多种来源，包括本地目录和云存储
    source_configs = [
        # 本地目录配置：处理指定路径下的文档文件
        {"type": "local_dir", "path": "/data/docs"},
        # S3存储配置：处理指定S3桶中特定前缀的文件
        {"type": "s3", "bucket": "mybucket", "prefix": "papers/"}
    ],
    
    # 解析器选项：配置不同文件类型的解析方式
    parser_opts = {
        # PDF解析配置：设置是否提取图像内容
        "pdf": {"extract_images": False}
    },
    
    # 文本分块选项：配置如何将大文档分割成小块
    chunker_opts = {
        # 使用滑动窗口策略进行分块
        "strategy": "sliding_window",
        # 每个文本块的大小为500个字符/词
        "window_size": 500,
        # 滑动步长为50，控制块之间的重叠程度
        "stride": 50
    },
    
    # 嵌入模型配置：使用OpenAI的文本嵌入模型
    embedder = OpenAIEmbedder(
        # 指定使用OpenAI的text-embedding-ada-002模型生成向量表示
        model="text-embedding-ada-002"
    ),
    
    # 存储配置：将处理结果保存到向量数据库
    storage = VectorDBStorage(
        # 向量数据库的主机地址
        host="localhost",
        # 向量数据库的端口号
        port=19530
    )
)

# 执行完整的处理流程：加载、解析、嵌入与存储
miner.process_all()
```

**​​关键组件说明：**​​
​- 1. **​SourceConnector​​** - 通过source_configs配置，支持从本地文件系统和S3存储加载文档
​- 2. **​DocumentParser​**​ - 通过parser_opts配置，处理PDF等格式的文档解析
​​- 3. **Segmenter/Chunker​**​ - 通过chunker_opts配置，使用滑动窗口策略分割文本
- 4. **​​Vectorizer/Embedder​**​ - 通过embedder配置，将文本转换为向量表示
​​- 5. **Storage Interface​​**- 通过storage配置，将向量数据持久化到向量数据库
**​​处理流程：​​**
process_all()方法自动执行：数据加载→文档解析→文本分块→向量嵌入→存储保存的完整流水线
这种配置适合构建RAG（检索增强生成）系统的知识库预处理环节

### 3.3 与Unstructured库优势对比分析
### 优势与对比分析

| 对比维度 | **MinerU** | **Unstructured** |
|-----------|-------------|------------------|
| **设计定位** | 提供完整非结构化数据处理管线（从加载、解析到嵌入存储） | 侧重文档解析与清洗 |
| **处理范围** | 支持文本、图像、表格、HTML 等多模态内容 | 主要支持文本类文件（PDF、Word、HTML 等） |
| **数据源支持** | 多数据源接入（本地文件、数据库、S3、网页等） | 主要为本地文件接口 |
| **模块化程度** | 高度模块化，可自由替换解析器、切片器、嵌入模型 | 模块较集中，扩展性较弱 |
| **元数据处理** | 支持丰富元数据抽取与上下文关联 | 元数据支持有限 |
| **嵌入与存储接口** | 内置多种向量化与存储适配（如 Milvus、Chroma） | 无内置嵌入与存储支持 |
| **多模态支持** | ✔ 支持 OCR、表格、图片提取 | ✖ 仅文本为主 |
| **性能表现** | 支持批处理与并行化，适合大规模数据 | 面向轻量场景，单机处理为主 |
| **学习成本** | 较高，需要理解各模块接口关系 | 较低，开箱即用 |
| **生态与社区** | 新兴项目，生态尚在发展中 | 社区成熟、资料丰富 |

## 四、总结
- 如果你要构建一个从 多个异构源（如文件系统 + 云存储 + 网页）统一处理的 RAG 系统，MinerU 是一个不错的选择；

- 如果你的非结构化数据还含有 图像、表格或 HTML 等混合格式，MinerU 的多模态支持更有优势；

- 在中小规模场景，或仅处理纯文本文件时，用 unstructured 可能更轻量简便；但随着规模和异构性上升，MinerU 的优势会逐渐凸显；

- 在使用时，可以与 LangChain、LlamaIndex 等框架结合，只将 MinerU 看成底层的 “数据加载 + 预处理” 层。