# 查询构建
前面我们提到了通过向量嵌入和相似度搜索处理非**结构化数据**检索信息。但在实际应用中，我们还需要处理很多结构化数据，处理的数据更加复杂和多多样化的数据。包括结构化数据（如SQL数据库）、半结构化数据（如带有元数据的文档）以及图数据。用户的查询也可能不仅仅是简单的语义匹配，而是包含复杂的过滤条件、聚合操作或关系查询。
这些查询通常有比较规则的、结构化的查询语言，因此使用向量检索查询的方式在结构化数据查询里可能有些表现不好，我们还需要结合LLM做一些改变。
**查询构建（Query Construction）**正是应对这一挑战的关键技术。它利用大语言模型（LLM）的强大理解能力，将用户的**自然语言查询“翻译”**成针对特定数据源的**结构化查询语言**或**带有过滤条件的请求**。这使得RAG系统能够无缝地连接和利用各种类型的数据，从而极大地**扩展了其应用场景和能力**。
## 一、文本到元数据过滤器
在构建向量索引时，常常会为文档快（Chunks）附加元数据（Metadata），例如文档开源、发布日期、作者、章节、类别等。这些元数据为我们提供了在语义搜索之外进行精确过滤的可能。

**自查询检索器（Self-Query Retriever）** 是LangChain中实现这一功能的核心组件。它的工作流程如下：
1. **定义元数据结构：**首先，需要向LLM清晰地描述文档内容和每个元数据字段的含义及类型。
2. **查询解析：**当用户输入一个自然语言查询时，自查询检索器会调用LLM，将查询分解为两部分：
    - **查询字符串（Query String）：**用于进行语义搜索的部分。
    - **元数据过滤器（Metadata Filter）：**从查询中提取出的结构化过滤条件。
3. **执行查询：**检索器将解析出的查询字符串和元数据过滤器发送给向量数据库，执行一次同时包含语义搜索和元数据过滤的查询。

例如，对于查询“关于2022年发布的机器学习的论文”，自查询检索器会将其解析为：
- **查询字符串:** "机器学习的论文"
- **元数据过滤器:** `year == 2022`

**代码示例**
接下来以B站视频为例来看看如何使用  `SelfQueryRetriever`
```python
import os
from langchain_deepseek import ChatDeepSeek  # DeepSeek语言模型接口
from langchain_community.document_loaders import BiliBiliLoader  # B站视频加载器
from langchain.chains.query_constructor.base import AttributeInfo  # 属性信息类
from langchain.retrievers.self_query.base import SelfQueryRetriever  # 自查询检索器
from langchain_community.vectorstores import Chroma  # Chroma向量数据库
from langchain_huggingface import HuggingFaceEmbeddings  # HuggingFace嵌入模型
import logging  # 日志模块

# 配置日志级别为INFO，便于调试和监控
logging.basicConfig(level=logging.INFO)

# 1. 初始化视频数据
# 定义要处理的B站视频URL列表
video_urls = [
    "https://www.bilibili.com/video/BV1Bo4y1A7FU",  # 视频1
    "https://www.bilibili.com/video/BV1ug4y157xA",  # 视频2
    "https://www.bilibili.com/video/BV1yh411V7ge",  # 视频3
]

bili = []  # 存储处理后的文档列表
try:
    # 创建BiliBiliLoader实例并加载视频数据
    # BiliBiliLoader.load() 返回值: List[Document] - 包含视频内容的文档列表
    loader = BiliBiliLoader(video_urls=video_urls)
    docs = loader.load()  # 加载视频数据，包括元数据和内容
    
    # 处理每个文档的元数据
    for doc in docs:
        original = doc.metadata  # 获取原始元数据
        
        # 提取并重构元数据字段
        metadata = {
            'title': original.get('title', '未知标题'),  # 视频标题，默认值'未知标题'
            'author': original.get('owner', {}).get('name', '未知作者'),  # 作者名称，嵌套获取
            'source': original.get('bvid', '未知ID'),  # 视频BVID，唯一标识符
            'view_count': original.get('stat', {}).get('view', 0),  # 观看次数，默认0
            'length': original.get('duration', 0),  # 视频时长（秒），默认0
        }
        
        doc.metadata = metadata  # 更新文档的元数据
        bili.append(doc)  # 添加到处理后的文档列表
        
except Exception as e:
    print(f"加载BiliBili视频失败: {str(e)}")  # 异常处理

# 检查是否成功加载了视频数据
if not bili:
    print("没有成功加载任何视频，程序退出")
    exit()  # 如果没有数据则退出程序

# 2. 创建向量存储
# 初始化HuggingFace嵌入模型
# HuggingFaceEmbeddings 返回值: 嵌入模型实例，提供embed_documents()方法
embed_model = HuggingFaceEmbeddings(model_name="BAAI/bge-small-zh-v1.5")  # 使用BAAI的中文小型嵌入模型

# 创建Chroma向量存储
# Chroma.from_documents() 参数说明:
# - documents: 要存储的文档列表
# - embedding: 嵌入模型实例
# - 返回值: Chroma向量存储实例，支持相似性搜索
vectorstore = Chroma.from_documents(bili, embed_model)
```
**关键组件详细说明：**
1. **BiliBiliLoader类**
- **​​功能​​:** 加载B站视频的标题、描述、弹幕、评论等内容
- ​**​返回值​​:** List[Document]，每个Document包含：
    - page_content: 视频文本内容
    - metadata: 视频元数据信息
2. **HuggingFaceEmbeddings类**
​- **​功能**​​: 提供文本到向量的嵌入功能
​- **​模型​**​: BAAI/bge-small-zh-v1.5- 专为中文优化的嵌入模型
​- **​返回值​**​: 嵌入向量数组，维度为512
3. **Chroma类**
​- **​功能**​​: 轻量级向量数据库，支持相似性搜索
​- **​主要方法**​​:
    - from_documents(): 从文档创建向量存储
    - similarity_search(): 执行相似性搜索
    - as_retriever(): 转换为检索器
4. **元数据处理逻辑**
原始元数据包含的字段：
```python
{
    'title': '视频标题',
    'owner': {'name': '作者名', 'mid': '作者ID'},
    'bvid': 'BVxxx',  # 视频唯一ID
    'stat': {'view': 观看数, 'danmaku': 弹幕数, 'reply': 回复数},
    'duration': 时长秒数,
    # ... 其他字段
}
```
处理后的标准化元数据：
```python
{
    'title': '标准化标题',
    'author': '作者名称', 
    'source': '视频BVID',
    'view_count': 观看次数,
    'length': 视频时长
}
```
这段代码构建了一个完整的视频内容处理管道，从B站视频加载到向量化存储，为后续的智能检索和问答做好了准备。
```python
# 3. 配置元数据字段信息
metadata_field_info = [
    AttributeInfo(
        name="title",
        description="视频标题（字符串）",
        type="string", 
    ),
    AttributeInfo(
        name="author",
        description="视频作者（字符串）",
        type="string",
    ),
    AttributeInfo(
        name="view_count",
        description="视频观看次数（整数）",
        type="integer",
    ),
    AttributeInfo(
        name="length",
        description="视频长度，以秒为单位的整数",
        type="integer"
    )
]

# 4. 创建自查询检索器
llm = ChatDeepSeek(
    model="deepseek-chat", 
    temperature=0, 
    api_key=os.getenv("DEEPSEEK_API_KEY")
    )

retriever = SelfQueryRetriever.from_llm(
    llm=llm,
    vectorstore=vectorstore,
    document_contents="记录视频标题、作者、观看次数等信息的视频元数据",
    metadata_field_info=metadata_field_info,
    enable_limit=True,
    verbose=True
)

# 5. 执行查询示例
queries = [
    "时间最短的视频",
    "时长大于600秒的视频"
]

for query in queries:
    print(f"\n--- 查询: '{query}' ---")
    results = retriever.invoke(query)
    if results:
        for doc in results:
            title = doc.metadata.get('title', '未知标题')
            author = doc.metadata.get('author', '未知作者')
            view_count = doc.metadata.get('view_count', '未知')
            length = doc.metadata.get('length', '未知')
            print(f"标题: {title}")
            print(f"作者: {author}")
            print(f"观看次数: {view_count}")
            print(f"时长: {length}秒")
            print("="*50)
    else:
        print("未找到匹配的视频")

```
这部分代码是实现自查询检索的核心。主要分为三个步骤：

1. **配置元数据字(metadata_field_info)** ：这是与LLM沟通的蓝图。通过`AttributeInfo` 为每个元数据字段定义名称、类型和一份清晰的自然语言`description`。LLM 将依赖这份描述来理解如何处理用户的查询，例如，它会根据“视频长度（整数）”的描述来解析关于“时长”的过滤和排序请求。因此，一份准确、无歧义的描述很重要。

2. **创建自查询检索器 (`SelfQueryRetriever.from_llm`)** ：from_llm 方法在底层执行了两个核心操作：

    - **加载查询构造器：**利用传入的 `llm、document_contents 和 metadata_field_info`，创建一个专门的“查询构造链”。这个链的核心职责是将用户的自然语言查询（如“时长大于600秒的视频”）转换为一个通用的、结构化的查询对象。

    - **获取内置翻译器：**接着，检查使用的向量数据库（这里是 `Chroma`），并为其匹配一个内置的“翻译器”。这个翻译器负责将上一步生成的通用查询对象，翻译成 `Chroma` 数据库能够原生理解和执行的过滤语法。

3. **执行查询 (`retriever.invoke`)** ：最后，用自然语言发起调用。检索器内部会依次执行“构造”和“翻译”两个步骤，最终向 Chroma 发起一个同时包含语义搜索和精确元数据过滤的复合查询，从而返回最相关的结果。

输出结果如下
```python
--- 查询: '时间最短的视频' ---
INFO:httpx:HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:langchain.retrievers.self_query.base:Generated Query: query=' ' filter=None limit=1
标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】02.Prompt 的构建原则
作者: 二次元的Datawhale
观看次数: 18788
时长: 1063秒
==================================================

--- 查询: '时长大于600秒的视频' ---
INFO:httpx:HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 200 OK"
INFO:langchain.retrievers.self_query.base:Generated Query: query=' ' filter=Comparison(comparator=<Comparator.GT: 'gt'>, attribute='length', value=600) limit=None
WARNING:chromadb.segment.impl.vector.local_hnsw:Number of requested results 4 is greater than number of elements in index 3, updating n_results = 3
标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】03.Prompt如何迭代优化
作者: 二次元的Datawhale
观看次数: 7090
时长: 806秒
==================================================
标题: 《吴恩达 x OpenAI Prompt课程》【专业翻译，配套代码笔记】02.Prompt 的构建原则
作者: 二次元的Datawhale
观看次数: 18788
时长: 1063秒
```

## 二、文本到Cypher
除了处理扁平化的元数据，查询构建技术还能应用于更复杂的数据结构，如图数据库。

### 2.1 什么是 Cypher？
Cypher 是图数据库（如 Neo4j）中最常用的查询语言，其地位类似于 SQL 之于关系数据库。它采用一种直观的方式来匹配图中的模式和关系，例如 `(:Person {name:"Tomaz"})-[:LIVES_IN]->(:Country {name:"Slovenia"})` 描述了一个人和一个国家以及他们之间的“居住在”关系。

### 2.2 “文本到Cypher”的原理
与“文本到元数据过滤器”类似，“文本到Cypher”技术利用大语言模型（LLM）将用户的自然语言问题直接翻译成一句精准的 Cypher 查询语句。LangChain 提供了相应的工具链（如 `GraphCypherQAChain`），其工作流程通常是：
1. 接收用户的自然语言问题。
2. LLM 根据预先提供的图谱模式（Schema），将问题转换为 Cypher 查询。
3. 在图数据库上执行该查询，获取精确的结构化数据。
4. (可选)将查询结果再次交由 LLM，生成通顺的自然语言答案。

由于生成有效的 Cypher 查询是一项复杂的任务，通常使用性能较强的 LLM 来确保转换的准确性。通过这种方式，用户可以用最自然的方式与高度结构化的图数据进行交互，极大地降低了数据查询的门槛。